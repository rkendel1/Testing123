# Provider-Agnostic Natural Language Architecture

## System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         VS Code Extension                        â”‚
â”‚                      (extensions/ai-coder)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â”‚ User enters natural language query
                 â”‚ (e.g., "Generate a function to calculate tax")
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Natural Language Query Command                      â”‚
â”‚  - naturalLanguageQueryCommand()                                 â”‚
â”‚  - generateCodeCommand()                                         â”‚
â”‚  - No provider-specific logic                                    â”‚
â”‚  - Uses unified interface                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â”‚ HTTP POST to /complete
                 â”‚ { prompt: "...", context: "..." }
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        AI Router Server                          â”‚
â”‚                      (ai-router/server.js)                       â”‚
â”‚                      http://localhost:3000                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â”‚ Read config.json to determine provider
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Configuration File                          â”‚
â”‚              /workspace/.aistudio/config.json                    â”‚
â”‚  {                                                                â”‚
â”‚    "provider": "ollama" or "openai" or "anthropic" etc.         â”‚
â”‚    "model": "codellama" or "gpt-4" or "claude-3" etc.           â”‚
â”‚    "apiKeys": { ... }                                            â”‚
â”‚  }                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â”‚ Route based on provider
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Provider Routing Logic                        â”‚
â”‚                                                                   â”‚
â”‚  switch (config.provider.toLowerCase()) {                        â”‚
â”‚    case 'ollama':   -> routeToOllama()                          â”‚
â”‚    case 'openai':   -> routeToOpenAI()                          â”‚
â”‚    case 'anthropic': -> routeToAnthropic()                      â”‚
â”‚    case 'mistral':  -> routeToMistral()                         â”‚
â”‚    case 'together': -> routeToTogether()                        â”‚
â”‚    case 'aider':    -> routeToAider()                           â”‚
â”‚  }                                                                â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚       â”‚          â”‚         â”‚          â”‚
    â–¼       â–¼          â–¼         â–¼          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Ollama  â”‚OpenAI  â”‚Anthropicâ”‚Mistral â”‚Togetherâ”‚     Aider          â”‚
â”‚        â”‚        â”‚         â”‚        â”‚        â”‚                    â”‚
â”‚Local   â”‚GPT-4   â”‚Claude   â”‚Mistral â”‚Open    â”‚Pair Programming   â”‚
â”‚Models  â”‚GPT-3.5 â”‚Models   â”‚Models  â”‚Source  â”‚Assistant           â”‚
â”‚        â”‚        â”‚         â”‚        â”‚Models  â”‚                    â”‚
â”‚Port    â”‚API     â”‚API      â”‚API     â”‚API     â”‚API                â”‚
â”‚11434   â”‚Endpointâ”‚Endpoint â”‚Endpointâ”‚Endpointâ”‚Endpoint            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚       â”‚          â”‚         â”‚          â”‚          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ Response (normalized format)
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        AI Router Server                          â”‚
â”‚                   (Normalize & Return Response)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â”‚ HTTP Response
                 â”‚ { data: "...", provider: "...", model: "..." }
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      VS Code Extension                           â”‚
â”‚                    (Display in Webview)                          â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ AI Natural Language Query                           â”‚        â”‚
â”‚  â”‚ Current Provider: ollama | Model: codellama         â”‚        â”‚
â”‚  â”‚ This interface works seamlessly with all providers  â”‚        â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤        â”‚
â”‚  â”‚ Query: Generate a function to calculate tax         â”‚        â”‚
â”‚  â”‚ [Send Query]                                         â”‚        â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤        â”‚
â”‚  â”‚ Response:                                            â”‚        â”‚
â”‚  â”‚ function calculateTax(amount, rate) {                â”‚        â”‚
â”‚  â”‚   return amount * (rate / 100);                      â”‚        â”‚
â”‚  â”‚ }                                                     â”‚        â”‚
â”‚  â”‚                                                       â”‚        â”‚
â”‚  â”‚ Response from provider: ollama                       â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Key Architectural Features

### 1. Abstraction Layer (AI Router)
- **Purpose**: Hide provider-specific API differences
- **Benefit**: Extension code stays provider-agnostic
- **Result**: Same code works with all providers

### 2. Configuration-Based Routing
- **File**: `/workspace/.aistudio/config.json`
- **What it does**: Tells router which provider to use
- **How to change**: Use `AI Coder: Select Provider` command
- **Effect**: Instant provider switching, no code changes

### 3. Unified Interface
- **Endpoint**: `/complete` for all providers
- **Request Format**: Same for all providers
  ```json
  {
    "prompt": "Natural language query",
    "context": "Optional context"
  }
  ```
- **Response Format**: Normalized across providers

### 4. Provider-Specific Routing Functions

Each provider has a dedicated routing function that handles its specific API:

```javascript
// Ollama - Local model
routeToOllama(prompt, model, stream)
  -> POST http://localhost:11434/api/generate

// OpenAI - Cloud API
routeToOpenAI(prompt, model, apiKey, stream)
  -> POST https://api.openai.com/v1/chat/completions
  -> Headers: Authorization: Bearer {apiKey}

// Anthropic - Cloud API
routeToAnthropic(prompt, model, apiKey, stream)
  -> POST https://api.anthropic.com/v1/messages
  -> Headers: x-api-key: {apiKey}

// Mistral - Cloud API
routeToMistral(prompt, model, apiKey, stream)
  -> POST https://api.mistral.ai/v1/chat/completions
  -> Headers: Authorization: Bearer {apiKey}

// Together AI - Cloud API
routeToTogether(prompt, model, apiKey, stream)
  -> POST https://api.together.xyz/v1/chat/completions
  -> Headers: Authorization: Bearer {apiKey}

// Aider - OpenAI-compatible API
routeToAider(prompt, model, apiKey, stream)
  -> POST https://api.aider.chat/v1/chat/completions
  -> Headers: Authorization: Bearer {apiKey}
```

## Data Flow Example

### Scenario: User generates tax calculation function with different providers

#### Step 1: User Input (Same for all providers)
```
Command: AI Coder: Natural Language Query
Input: "Generate a function to calculate tax"
```

#### Step 2: Extension Processing (Same for all providers)
```javascript
// In naturalLanguageQueryCommand()
const response = await axios.post(`${routerUrl}/complete`, {
  prompt: "Generate a function to calculate tax",
  context: ""
});
```

#### Step 3: Router Processing

**With Ollama**:
```javascript
// config.provider = 'ollama'
case 'ollama':
  providerResponse = await routeToOllama(
    "Generate a function to calculate tax",
    "codellama",
    true
  );
  // -> POST to http://localhost:11434/api/generate
```

**With OpenAI**:
```javascript
// config.provider = 'openai'
case 'openai':
  providerResponse = await routeToOpenAI(
    "Generate a function to calculate tax",
    "gpt-4",
    apiKey,
    true
  );
  // -> POST to https://api.openai.com/v1/chat/completions
```

**With Anthropic**:
```javascript
// config.provider = 'anthropic'
case 'anthropic':
  providerResponse = await routeToAnthropic(
    "Generate a function to calculate tax",
    "claude-3-opus",
    apiKey,
    true
  );
  // -> POST to https://api.anthropic.com/v1/messages
```

#### Step 4: Response Display (Same for all providers)
```javascript
// Extension receives response and displays it
panel.webview.postMessage({
  command: 'receiveResponse',
  text: response.data,
  originalQuery: "Generate a function to calculate tax",
  provider: currentProvider // Shows which provider responded
});
```

## Provider Switching Flow

```
User Action: AI Coder: Select Provider
                    â†“
            Choose "anthropic"
                    â†“
    Update /workspace/.aistudio/config.json
                    â†“
         {"provider": "anthropic", ...}
                    â†“
            Status Bar Updates
                    â†“
      "ðŸ¤– AI: anthropic/claude-3"
                    â†“
    Next query uses Anthropic
                    â†“
      (No code changes needed!)
```

## Benefits of This Architecture

### For Users:
âœ… **Learn Once**: Same commands for all providers
âœ… **Switch Freely**: Change providers anytime
âœ… **Compare Easily**: Test same query with different providers
âœ… **Optimize Costs**: Use free local or paid cloud as needed

### For Developers:
âœ… **Simple Extension Code**: No provider-specific logic
âœ… **Easy to Extend**: Add new providers to router only
âœ… **Maintainable**: Changes in one place (router)
âœ… **Testable**: Clear separation of concerns

### For the System:
âœ… **Scalable**: Add providers without touching extension
âœ… **Reliable**: Provider failures isolated
âœ… **Flexible**: Different providers for different tasks
âœ… **Cacheable**: Responses cached at router level

## Summary

The architecture ensures that:
1. **Users** never need to know provider-specific details
2. **Extension code** remains provider-agnostic
3. **AI Router** handles all provider complexity
4. **Natural language** works uniformly everywhere
5. **Provider switching** is seamless and instant

This is true provider-agnostic design: write your natural language query once, use it with any provider, switch providers freely, all through the same unified interface.
